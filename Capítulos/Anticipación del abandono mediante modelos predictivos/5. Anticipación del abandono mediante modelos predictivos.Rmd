---
title: "5. Anticipación del abandono mediante modelos predictivos"
author: "Pablo Parrilla Cañadas"
date: "2025-06-05"
output: pdf_document
---

Librerías

```{r warning=FALSE}
rm(list=ls())
library(dplyr)
library(fastDummies)
library(grid)
library(cluster)
library(factoextra)
library(caret)
library(gridExtra)

library(DMwR2)
library(themis)
library(recipes)
library(ROSE)
library(smotefamily)
library(randomForest)
library(UBL)
library(rpart)
library(rpart.plot)
library(xgboost)
library(class)
library(caret)
```

```{r}
load("../../Datos/Capítulos/Caracterización.Rdata")
```


```{r}
# 1. Preparar dataset 'ambas'
ambas = academicas %>% left_join(select(sociodemografia, -c("abandono")), by = "dni_hash")
ambas$nota14[is.na(ambas$nota14)] = median(ambas$nota14, na.rm = TRUE)

ambas <- ambas %>%
  select(
    -rendimiento_cuat_a,
    -rendimiento_total,
    -actividades,
    -ajuste,
    -pract1,
    -activ1,
    -total1,
    -rend_total_ultimo,
    -rend_total_penultimo,
    -rend_total_antepenultimo
  )

ambas_prep = ambas[, 2:length(ambas)]

# 2. Imputación por kNN (excepto abandono que es factor)
ambas_limpio <- VIM::kNN(ambas_prep, k = 5, imp_var = FALSE)

# 3. Asegurar que abandono sea factor
ambas_limpio$abandono = as.factor(ambas_limpio$abandono)

# 4. PCA de poliformat (no se toca)
num_vars = poliformat %>% select(where(is.numeric))
num_vars = num_vars[, 2:length(num_vars)]
pca_poliformat = prcomp(num_vars, scale. = TRUE)
pca_df = pca_poliformat$x[, 1:6]

# 5. Combinar con ambas_limpio
final_dataset = as.data.frame(cbind(ambas_limpio[, 2:ncol(ambas_limpio)], pca_df))

y <- final_dataset$abandono
X <- final_dataset %>%
  select(-abandono) %>%
  dummy_cols(remove_selected_columns = TRUE, remove_first_dummy = TRUE)

final_dataset_dummies <- bind_cols(X, abandono = y)
final_dataset_dummies$abandono <- as.factor(final_dataset_dummies$abandono)

final_dataset_dummies[,-83] <- final_dataset_dummies[-83] %>%
  select(-which(grepl("Desconocido", names(.)) & colSums(.) == 0))
```

final_dataset_dummies
Vamos probar varias técnicas de resampling.


 # Smote

```{r}
balanced_data=SMOTE(final_dataset_dummies[,-83],final_dataset_dummies$abandono,K = 5,dup_size = 2 )
datos_smote=balanced_data$data
colnames(datos_smote)[ncol(datos_smote)] <- "abandono"
table(datos_smote$abandono)

```

# Rose

```{r}
n_majority=sum(final_dataset_dummies$abandono==0)
n_minority_target=52*3
n_total=n_majority + n_minority_target

rose_out=ROSE( abandono ~ ., data = final_dataset_dummies, N = n_total, p = n_minority_target/n_total,seed = 20)$data

table(rose_out$abandono)
```


Árbol


```{r}
# Con SMOTE
arbol_smote <- rpart(abandono ~ ., data = datos_smote, method = "class")
rpart.plot(arbol_smote)
printcp(arbol_smote)

# Con ROSE
arbol_rose <- rpart(abandono ~ ., data = rose_out, method = "class")
rpart.plot(arbol_rose)
printcp(arbol_rose)
```

Random Forest

```{r fig.height=6.5}
# SMOTE
datos_smoke_rf=datos_smote
rose_out_rf=rose_out

datos_smoke_rf$abandono=as.numeric(datos_smoke_rf$abandono)
rose_out_rf$abandono=as.numeric(rose_out_rf$abandono)
rose_out_rf$abandono=rose_out_rf$abandono-1

rf_smote <- randomForest(abandono ~ ., data = datos_smoke_rf, importance = TRUE)
print(rf_smote)
varImpPlot(rf_smote)

# ROSE
rf_rose <- randomForest(abandono ~ ., data = rose_out_rf, importance = TRUE)
print(rf_rose)
varImpPlot(rf_rose)
```

gboost

```{r}
# Preparar matrices
X_smote <- model.matrix(abandono ~ ., data = datos_smote)
y_smote <- as.numeric(datos_smote$abandono) 

X_rose <- model.matrix(abandono ~ ., data = rose_out_rf)
y_rose <- as.numeric(rose_out_rf$abandono)

# SMOTE
xgb_smote <- xgboost(data = X_smote, label = y_smote, nrounds = 100, objective = "binary:logistic", verbose = 0)
# ROSE
xgb_rose <- xgboost(data = X_rose, label = y_rose, nrounds = 100, objective = "binary:logistic", verbose = 0)
```


Regresión Logística

```{r}
glm_smote <- glm(abandono ~ ., data = datos_smoke_rf, family = "binomial")
summary(glm_smote)

# ROSE
glm_rose <- glm(abandono ~ ., data = rose_out_rf, family = "binomial")
summary(glm_rose)
```


```{r}
# Preprocesado
preproc_smote <- preProcess(select(datos_smote, -abandono), method = c("center", "scale"))
X_knn_smote <- predict(preproc_smote, select(datos_smote, -abandono))
y_knn_smote <- datos_smote$abandono

preproc_rose <- preProcess(select(rose_out, -abandono), method = c("center", "scale"))
X_knn_rose <- predict(preproc_rose, select(rose_out, -abandono))
y_knn_rose <- rose_out$abandono

# Entrenar/test split
set.seed(123)
trainIndex <- createDataPartition(y_knn_smote, p = .8, list = FALSE)

# SMOTE
knn_smote_pred <- knn(train = X_knn_smote[trainIndex,], test = X_knn_smote[-trainIndex,],
                      cl = y_knn_smote[trainIndex], k = 5)

# Convertir ambos a factores con los mismos niveles
pred_f_smote <- factor(knn_smote_pred, levels = c(0,1))
true_f_smote <- factor(y_knn_smote[-trainIndex], levels = c(0,1))

confusionMatrix(pred_f_smote, true_f_smote,positive = "1")


print("")

# ROSE
trainIndex2 <- createDataPartition(y_knn_rose, p = .8, list = FALSE)
knn_rose_pred <- knn(train = X_knn_rose[trainIndex2,], test = X_knn_rose[-trainIndex2,],
                     cl = y_knn_rose[trainIndex2], k = 5)

pred_f_rose <- factor(knn_rose_pred, levels = c(0,1))
true_f_rose <- factor(y_knn_rose[-trainIndex2], levels = c(0,1))

confusionMatrix(pred_f_rose, true_f_rose, positive="1")
```

```{r}
datos=datos_smoke_rf

grupo <- as.factor(datos$abandono)
datos <- datos %>% select(-abandono)

cols_con_na_en_abandono <- datos %>%
  select(where(~ any(is.na(.)))) %>%
  names()

datos <- datos %>% select(-all_of(cols_con_na_en_abandono))

num_vars <- datos %>% select(where(is.numeric))

datos_pca <- datos %>%
  select(where(~ var(., na.rm = TRUE) > 0))

pca_result <- prcomp(datos_pca, scale. = TRUE)
```


```{r}

a=fviz_pca_ind(pca_result,
             geom.ind = "point",
             col.ind = grupo,
             palette = c("steelblue", "tomato"),
             addEllipses = TRUE,
             legend.title = "Abandono") +
  theme_minimal()

b=fviz_pca_ind(pca_result,
             geom.ind = "point",
             col.ind = grupo,
             palette = c("steelblue", "tomato"),
             addEllipses = TRUE,
             legend.title = "Abandono",axes=c(3,4)) +
            
  theme_minimal()


c=fviz_pca_ind(pca_result,
             geom.ind = "point",
             col.ind = grupo,
             palette = c("steelblue", "tomato"),
             addEllipses = TRUE,
             legend.title = "Abandono",axes=c(5,6)) +
            
  theme_minimal()

d=fviz_pca_ind(pca_result,
             geom.ind = "point",
             col.ind = grupo,
             palette = c("steelblue", "tomato"),
             addEllipses = TRUE,
             legend.title = "Abandono",axes=c(7,8)) +
            
  theme_minimal()

grid.arrange(a,b,c,d,ncol=2)
```

